{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "12a7f015",
      "metadata": {
        "id": "12a7f015"
      },
      "source": [
        "### Image Data Inspection\n",
        "\n",
        "**Q1. What is COCO?**\n",
        "\n",
        "`COCO` stands for `Common Objects in Context`. It's a large, publicly available dataset of images used to train and test computer vision models for tasks like object detection and image segmentation.\n",
        "\n",
        "**Q2. What does it Contain?**\n",
        "\n",
        "The `COCO 2017` dataset contains hundreds of thousands of real-world photographs with detailed annotations. Each image typically has multiple objects of different types, and each object is carefully labeled with:\n",
        "\n",
        "- A bounding box (rectangular border around the object)\n",
        "\n",
        "- A segmentation mask (precise pixel-level outline of the object)\n",
        "\n",
        "- The object's category/class name (e.g., \"person\", \"car\", \"dog\")\n",
        "\n",
        "- Dataset Size:\n",
        "\n",
        "  - 118,000 training images (for teaching the model)\n",
        "\n",
        "  - 5,000 validation images (for testing during training)\n",
        "\n",
        "  - 40,700 test images (for final model evaluation)\n",
        "\n",
        "  - 80 object categories to detect (things like people, animals, vehicles, furniture, etc.)\n",
        "\n",
        "  - Over 1.5 million labeled objects across all images\n",
        "\n",
        "**Q3. How is it organized?**\n",
        "\n",
        "The dataset has a folder structure with:\n",
        "\n",
        "- Images folder: Contains actual `.jpg` image files\n",
        "\n",
        "- Annotations folder: Contains `JSON` files with all the labeling information (bounding boxes, masks, categories, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebddce79",
      "metadata": {
        "id": "ebddce79"
      },
      "source": [
        "#### Import Libraries and Set Paths\n",
        "- Set up the environment by importing necessary libraries and defining the paths to your COCO dataset folders and annotation files."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle, Polygon\n",
        "\n",
        "# Path to extract COCO Dataset\n",
        "coco_root = r\"A:\\img\\coco2017\"  # e.g., \"coco_2017\"\n",
        "images_dir = os.path.join(coco_root, \"train2017\")  # or val2017\n",
        "annotations_file = os.path.join(coco_root, \"annotations\", \"instances_train2017.json\")"
      ],
      "metadata": {
        "id": "WWrwr-lqbRB2"
      },
      "id": "WWrwr-lqbRB2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load COCO Annotations\n",
        "- Now load up the `COCO JSON` annotation file and parses it into Python dictionaries for efficient data access."
      ],
      "metadata": {
        "id": "EDKis5D3bxcG"
      },
      "id": "EDKis5D3bxcG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load COCO annotations\n",
        "with open(annotations_file, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Create dictionaries for quick lookup\n",
        "images_by_id = {img['id']: img for img in coco_data['images']}\n",
        "categories_by_id = {cat['id']: cat for cat in coco_data['categories']}\n",
        "\n",
        "# Group annotations by image_id\n",
        "annotations_by_image = {}\n",
        "for ann in coco_data['annotations']:\n",
        "    img_id = ann['image_id']\n",
        "    if img_id not in annotations_by_image:\n",
        "        annotations_by_image[img_id] = []\n",
        "    annotations_by_image[img_id].append(ann)\n",
        "\n",
        "print(f\"Total images: {len(coco_data['images'])}\")\n",
        "print(f\"Total categories: {len(coco_data['categories'])}\")\n",
        "print(f\"Total annotations: {len(coco_data['annotations'])}\")"
      ],
      "metadata": {
        "id": "kWbuAd2Fb06w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "01f27023-7447-4dfa-92a2-622f993a29be"
      },
      "id": "kWbuAd2Fb06w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'A:\\\\img\\\\coco2017/annotations/instances_train2017.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4104063435.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load COCO annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcoco_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create dictionaries for quick lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'A:\\\\img\\\\coco2017/annotations/instances_train2017.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Display Dataset Statistics\n",
        "- This function analyzes the entire dataset and prints statistics about object distribution across categories to understand dataset composition.\n",
        "\n"
      ],
      "metadata": {
        "id": "HRTgcDZIcFNm"
      },
      "id": "HRTgcDZIcFNm"
    },
    {
      "cell_type": "code",
      "source": [
        "def print_dataset_stats():\n",
        "    print(\"\\n--- Dataset Statistics ---\")\n",
        "    category_counts = {}\n",
        "    for ann in coco_data['annotations']:\n",
        "        cat_id = ann['category_id']\n",
        "        cat_name = categories_by_id[cat_id]['name']\n",
        "        category_counts[cat_name] = category_counts.get(cat_name, 0) + 1\n",
        "\n",
        "    print(\"\\nObject counts per category (top 10):\")\n",
        "    sorted_cats = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "    for cat_name, count in sorted_cats:\n",
        "        print(f\"  {cat_name}: {count}\")\n",
        "print_dataset_stats()"
      ],
      "metadata": {
        "id": "iNs2fKcdcIfC"
      },
      "id": "iNs2fKcdcIfC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ef743507",
      "metadata": {
        "id": "ef743507"
      },
      "source": [
        "#### Inspect Single Image with Annotations\n",
        "- This core function that loads a specific image by ID and displays its metadata, objects, and visualizations with bounding boxes and segmentation masks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_image_with_annotations(image_id, visualize_bbox=True, visualize_mask=True):\n",
        "    # Load image\n",
        "    image_info = images_by_id[image_id]\n",
        "    image_path = os.path.join(images_dir, image_info['file_name'])\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Print image info\n",
        "    print(f\"\\n--- Image Inspection ---\")\n",
        "    print(f\"Image ID: {image_id}\")\n",
        "    print(f\"Filename: {image_info['file_name']}\")\n",
        "    print(f\"Size: {image.size} (width x height)\")\n",
        "    print(f\"Mode: {image.mode}\")\n",
        "\n",
        "    # Get annotations for this image\n",
        "    annotations = annotations_by_image.get(image_id, [])\n",
        "    print(f\"Number of objects: {len(annotations)}\")\n",
        "\n",
        "    # Print object categories in this image\n",
        "    print(\"\\nObjects in this image:\")\n",
        "    for ann in annotations:\n",
        "        cat_id = ann['category_id']\n",
        "        cat_name = categories_by_id[cat_id]['name']\n",
        "        bbox = ann['bbox']\n",
        "        area = ann['area']\n",
        "        print(f\"  - {cat_name}: bbox={bbox}, area={area:.0f}px\")\n",
        "\n",
        "    # Visualize\n",
        "    if visualize_bbox or visualize_mask:\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
        "        ax.imshow(image)\n",
        "\n",
        "        # Draw bounding boxes\n",
        "        if visualize_bbox:\n",
        "            for ann in annotations:\n",
        "                bbox = ann['bbox']\n",
        "                x, y, w, h = bbox\n",
        "                rect = Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "                cat_id = ann['category_id']\n",
        "                cat_name = categories_by_id[cat_id]['name']\n",
        "                ax.text(x, y-5, cat_name, fontsize=8, color='red',\n",
        "                       bbox=dict(facecolor='white', alpha=0.7))\n",
        "\n",
        "        # Draw segmentation masks\n",
        "        if visualize_mask:\n",
        "            for ann in annotations:\n",
        "                if 'segmentation' in ann and len(ann['segmentation']) > 0:\n",
        "                    seg = ann['segmentation'][0]  # Get first polygon\n",
        "                    if isinstance(seg, list) and len(seg) > 4:\n",
        "                        # Reshape to (N, 2) for polygon\n",
        "                        polygon = np.array(seg).reshape(-1, 2)\n",
        "                        poly = Polygon(polygon, alpha=0.3, color='blue')\n",
        "                        ax.add_patch(poly)\n",
        "\n",
        "        ax.axis('off')\n",
        "        ax.set_title(f\"Image ID: {image_id}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "tG2vb4MybsI2"
      },
      "id": "tG2vb4MybsI2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "89dcc77d",
      "metadata": {
        "id": "89dcc77d"
      },
      "source": [
        "#### Inspect Image by Index\n",
        "\n",
        "- This helper function allows to inspect images by their position in the dataset (0, 1, 2, etc.) without needing to know the image ID."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_image_by_index(index=0):\n",
        "    image_ids = list(images_by_id.keys())\n",
        "    if index < len(image_ids):\n",
        "        image_id = image_ids[index]\n",
        "        inspect_image_with_annotations(image_id, visualize_bbox=True, visualize_mask=True)\n",
        "    else:\n",
        "        print(f\"Index {index} out of range. Total images: {len(image_ids)}\")\n",
        "\n",
        "inspect_image_by_index(index=0)"
      ],
      "metadata": {
        "id": "W5CUY04IdLaJ"
      },
      "id": "W5CUY04IdLaJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "37538d5e",
      "metadata": {
        "id": "37538d5e"
      },
      "source": [
        "#### Inspect Random Images\n",
        "\n",
        "- This function randomly selects and inspects multiple images from the dataset to get a diverse view of different samples."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_random_images(num_samples=3):\n",
        "    import random\n",
        "    random_image_ids = random.sample(list(images_by_id.keys()), num_samples)\n",
        "\n",
        "    for img_id in random_image_ids:\n",
        "        inspect_image_with_annotations(img_id, visualize_bbox=True, visualize_mask=True)\n",
        "\n",
        "inspect_random_images(num_samples=3)"
      ],
      "metadata": {
        "id": "KB2rVXT5dgWl"
      },
      "id": "KB2rVXT5dgWl",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}